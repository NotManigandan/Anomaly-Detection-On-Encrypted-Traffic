{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74873e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import sys\n",
    "import tenseal as ts\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce093d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client Side\n",
    "def create_context(N, q, scale, galois = False):\n",
    "    poly_mod_degree = N\n",
    "    coeff_mod_bit_sizes = q\n",
    "    ctx = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "    ctx.global_scale = 2 ** scale\n",
    "    if galois == True:\n",
    "        ctx.generate_galois_keys()\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5249d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client Side\n",
    "def load_prepare_input(context, csv_path, model, n = None, m = None):\n",
    "    # Importing the data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.drop(df[df.Protocol  == 'Protocol'].index)\n",
    "    cols = ['Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n",
    "            'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n",
    "            'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
    "            'Fwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
    "            'Flow IAT Std', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Min',\n",
    "            'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Bwd Packets/s',\n",
    "            'Packet Length Max', 'FIN Flag Count', 'RST Flag Count',\n",
    "            'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'Down/Up Ratio',\n",
    "            'FWD Init Win Bytes', 'Bwd Init Win Bytes',\n",
    "            'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Label']\n",
    "    org_cols_names = ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
    "       'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
    "       'Fwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
    "       'Flow IAT Std', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Min',\n",
    "       'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Bwd Packets/s',\n",
    "       'Max Packet Length', 'FIN Flag Count', 'RST Flag Count',\n",
    "       'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'Down/Up Ratio',\n",
    "       'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\n",
    "       'min_seg_size_forward', 'Active Mean', 'Active Std', 'Label']\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Scaling\n",
    "    df.columns= org_cols_names\n",
    "    x = df.drop('Label', axis=1)\n",
    "    scaler_path = r\"C:\\Users\\manig\\Downloads\\Mitacs\\Anomaly-Detection-On-Encrypted-Traffic\\Code\\scaler.pkl\"\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    x = scaler.transform(x)\n",
    "    \n",
    "    #  If the model we are using is CNN, we have to reshape and perform im2col encoding\n",
    "    windows_nb = None\n",
    "    if model == \"CNN\":\n",
    "        x = x.reshape(len(df), n, m)\n",
    "        x = torch.from_numpy(x).float().unsqueeze(1)\n",
    "        enc_x, windows_nb = ts.im2col_encoding(context, data.view(n, m).tolist(), 3, 3, 1)\n",
    "    else:\n",
    "        enc_x = []\n",
    "        x = torch.from_numpy(x).float()\n",
    "        for i in range(100):\n",
    "            enc_x.append(ts.ckks_vector(context, x[i].tolist()))\n",
    "        \n",
    "\n",
    "    return enc_x, windows_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad0649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def serialize_input(context, enc_x):\n",
    "#     server_context = context.copy()\n",
    "#     server_context.make_context_public()\n",
    "#     server_context = server_context.serialize()\n",
    "#     for i in range(len(enc_x)):\n",
    "#         enc_x[i] =  enc_x[i].serialize()\n",
    "#     encrypted_input = enc_x\n",
    "    \n",
    "#     client_data = {\n",
    "#         \"context\" : server_context,\n",
    "#         \"data\" : encrypted_input\n",
    "#     }\n",
    "\n",
    "    \n",
    "#     return client_data\n",
    "\n",
    "# Client Side\n",
    "def serialize_input(context, enc_x):\n",
    "    server_context = context.copy()\n",
    "    server_context.make_context_public()\n",
    "    server_context = base64.b64encode(server_context.serialize()).decode()\n",
    "\n",
    "    encrypted_input = []\n",
    "    for i in range(len(enc_x)):\n",
    "        serialized = base64.b64encode(enc_x[i].serialize()).decode()\n",
    "        encrypted_input.append(serialized)\n",
    "    \n",
    "    client_data = {\n",
    "        \"context\" : server_context,\n",
    "        \"data\" : encrypted_input\n",
    "    }\n",
    "\n",
    "    return json.dumps(client_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f818f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [60, 40, 60]\n",
    "scl = 40\n",
    "ctx = create_context(poly_mod_degree, coeff_mod_bit_sizes, scl, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725250b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manig\\AppData\\Local\\Temp\\ipykernel_17152\\2977563453.py:4: DtypeWarning: Columns (2,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    }
   ],
   "source": [
    "enc_ip, windows_nb = load_prepare_input(ctx, csv_path = r\"C:\\Users\\manig\\Downloads\\Mitacs\\Anomaly-Detection-On-Encrypted-Traffic\\main\\test_ISCX.csv\", model=\"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adfa5d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "send = serialize_input(ctx, enc_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f5745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b3a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preapre_client_data(client_json):\n",
    "    data = json.loads(client_json)  \n",
    "    server_context = base64.b64decode(data[\"context\"])\n",
    "    context = ts.context_from(server_context)\n",
    "    encrypted_input = []\n",
    "    for enc in data['data']:\n",
    "        enc = base64.b64decode(enc)\n",
    "        encrypted_input.append(ts.ckks_vector_from(context, enc))\n",
    "    return context, encrypted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f738bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_no_sk, encrypted_input = preapre_client_data(send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fd8afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from pathlib import Path\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_NAME = \"lr.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "model = models.LR(30)\n",
    "model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "\n",
    "eelr = models.EncryptedLR(model)\n",
    "server_output = models.encrypted_evaluation(eelr, encrypted_input)\n",
    "encrypted_output = []\n",
    "for i in range(len(server_output)):\n",
    "    serialized = base64.b64encode(server_output[i].serialize()).decode()\n",
    "    encrypted_output.append(serialized)\n",
    "server_response = {\n",
    "    \"data\" : encrypted_output\n",
    "}\n",
    "server_response = json.dumps(server_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a006e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(server_response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80ac6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_output = []\n",
    "for enc in data['data']:\n",
    "    enc = base64.b64decode(enc)\n",
    "    encrypted_output.append(ts.ckks_vector_from(ctx, enc).decrypt())\n",
    "op = torch.sigmoid(torch.tensor(encrypted_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba5e0a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0020],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0020],\n",
       "        [0.0000],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0020],\n",
       "        [0.0018],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4e437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
