{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37e53658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c68934f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([681185, 40])\n",
      "y_train shape: torch.Size([681185, 1])\n",
      "x_test shape: torch.Size([170297, 40])\n",
      "y_test shape: torch.Size([170297, 1])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\invite1\\Downloads\\Manigandan Ramadasan\\Code\\top_feature_df.csv\")\n",
    "grouped = df.groupby('Label')\n",
    "df = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "x = df.drop([\"Label\"], axis = 1)\n",
    "y = df[\"Label\"]\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x_train, x_test_20, y_train, y_test_20 = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "x_train=torch.from_numpy(x_train).float()\n",
    "x_test_20=torch.from_numpy(x_test_20).float()\n",
    "y_train=torch.from_numpy(np.array(y_train)).float().unsqueeze(1)\n",
    "y_test_20=torch.from_numpy(np.array(y_test_20)).float().unsqueeze(1)\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test_20.shape}\")\n",
    "print(f\"y_test shape: {y_test_20.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f87605f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84033640",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=n_features, out_features=32)\n",
    "        self.layer_2 = nn.Linear(in_features=32, out_features=16)\n",
    "        self.layer_3 = nn.Linear(in_features=16, out_features=8)\n",
    "        self.layer_4 = nn.Linear(in_features=8, out_features=4)\n",
    "        self.layer_5 = nn.Linear(in_features=4, out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = x*x\n",
    "#         x = self.relu(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = x*x\n",
    "#         x = self.relu(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = x*x\n",
    "#         x = self.relu(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = x*x\n",
    "#         x = self.relu(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "        x = self.layer_5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "158db3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, criterion, scheduler, x, y, epochs):\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    loss_dict = {}\n",
    "    for e in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step(loss)\n",
    "        loss_dict[e] = loss.data\n",
    "        if e%10 == 0:\n",
    "            print(f\"Loss at epoch {e}: {loss.data} || Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    return model, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65898926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3dbae0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (layer_1): Linear(in_features=40, out_features=32, bias=True)\n",
      "  (layer_2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (layer_3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (layer_4): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (layer_5): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Loss at epoch 10: 0.6156454682350159\n",
      "Learning Rate at 10: 0.01\n",
      "Loss at epoch 20: 0.5991216897964478\n",
      "Learning Rate at 20: 0.01\n",
      "Loss at epoch 30: 0.5712631344795227\n",
      "Learning Rate at 30: 0.01\n",
      "Loss at epoch 40: 0.502305269241333\n",
      "Learning Rate at 40: 0.01\n",
      "Loss at epoch 50: 0.42768627405166626\n",
      "Learning Rate at 50: 0.01\n",
      "Loss at epoch 60: 0.37459564208984375\n",
      "Learning Rate at 60: 0.01\n",
      "Loss at epoch 70: 0.322366863489151\n",
      "Learning Rate at 70: 0.01\n",
      "Loss at epoch 80: 0.292977511882782\n",
      "Learning Rate at 80: 0.01\n",
      "Loss at epoch 90: 0.2556629776954651\n",
      "Learning Rate at 90: 0.01\n",
      "Loss at epoch 100: 0.23921500146389008\n",
      "Learning Rate at 100: 0.01\n",
      "Loss at epoch 110: 0.2307107299566269\n",
      "Learning Rate at 110: 0.01\n",
      "Loss at epoch 120: 0.21569199860095978\n",
      "Learning Rate at 120: 0.01\n",
      "Loss at epoch 130: 0.19927068054676056\n",
      "Learning Rate at 130: 0.01\n",
      "Loss at epoch 140: 0.1955878585577011\n",
      "Learning Rate at 140: 0.01\n",
      "Loss at epoch 150: 0.3337497115135193\n",
      "Learning Rate at 150: 0.01\n",
      "Loss at epoch 160: 0.20031166076660156\n",
      "Learning Rate at 160: 0.001\n",
      "Loss at epoch 170: 0.1947537362575531\n",
      "Learning Rate at 170: 0.0001\n",
      "Loss at epoch 180: 0.19399414956569672\n",
      "Learning Rate at 180: 1e-05\n",
      "Loss at epoch 190: 0.1938825100660324\n",
      "Learning Rate at 190: 1.0000000000000002e-06\n",
      "Loss at epoch 200: 0.19386056065559387\n",
      "Learning Rate at 200: 1.0000000000000002e-06\n",
      "Loss at epoch 210: 0.19385720789432526\n",
      "Learning Rate at 210: 1.0000000000000002e-07\n",
      "Loss at epoch 220: 0.19385682046413422\n",
      "Learning Rate at 220: 1.0000000000000004e-08\n",
      "Loss at epoch 230: 0.19385677576065063\n",
      "Learning Rate at 230: 1.0000000000000004e-08\n",
      "Loss at epoch 240: 0.19385670125484467\n",
      "Learning Rate at 240: 1.0000000000000004e-08\n",
      "Loss at epoch 250: 0.19385665655136108\n",
      "Learning Rate at 250: 1.0000000000000004e-08\n",
      "Loss at epoch 260: 0.1938566118478775\n",
      "Learning Rate at 260: 1.0000000000000004e-08\n",
      "Loss at epoch 270: 0.19385655224323273\n",
      "Learning Rate at 270: 1.0000000000000004e-08\n",
      "Loss at epoch 280: 0.19385650753974915\n",
      "Learning Rate at 280: 1.0000000000000004e-08\n",
      "Loss at epoch 290: 0.19385643303394318\n",
      "Learning Rate at 290: 1.0000000000000004e-08\n",
      "Loss at epoch 300: 0.1938564032316208\n",
      "Learning Rate at 300: 1.0000000000000004e-08\n",
      "Loss at epoch 310: 0.193856343626976\n",
      "Learning Rate at 310: 1.0000000000000004e-08\n",
      "Loss at epoch 320: 0.19385626912117004\n",
      "Learning Rate at 320: 1.0000000000000004e-08\n",
      "Loss at epoch 330: 0.19385622441768646\n",
      "Learning Rate at 330: 1.0000000000000004e-08\n",
      "Loss at epoch 340: 0.19385617971420288\n",
      "Learning Rate at 340: 1.0000000000000004e-08\n",
      "Loss at epoch 350: 0.1938561052083969\n",
      "Learning Rate at 350: 1.0000000000000004e-08\n",
      "Loss at epoch 360: 0.19385604560375214\n",
      "Learning Rate at 360: 1.0000000000000004e-08\n",
      "Loss at epoch 370: 0.19385597109794617\n",
      "Learning Rate at 370: 1.0000000000000004e-08\n",
      "Loss at epoch 380: 0.19385592639446259\n",
      "Learning Rate at 380: 1.0000000000000004e-08\n",
      "Loss at epoch 390: 0.19385583698749542\n",
      "Learning Rate at 390: 1.0000000000000004e-08\n",
      "Loss at epoch 400: 0.19385579228401184\n",
      "Learning Rate at 400: 1.0000000000000004e-08\n",
      "Loss at epoch 410: 0.19385571777820587\n",
      "Learning Rate at 410: 1.0000000000000004e-08\n",
      "Loss at epoch 420: 0.1938556581735611\n",
      "Learning Rate at 420: 1.0000000000000004e-08\n",
      "Loss at epoch 430: 0.19385561347007751\n",
      "Learning Rate at 430: 1.0000000000000004e-08\n",
      "Loss at epoch 440: 0.19385553896427155\n",
      "Learning Rate at 440: 1.0000000000000004e-08\n",
      "Loss at epoch 450: 0.19385546445846558\n",
      "Learning Rate at 450: 1.0000000000000004e-08\n",
      "Loss at epoch 460: 0.1938553750514984\n",
      "Learning Rate at 460: 1.0000000000000004e-08\n",
      "Loss at epoch 470: 0.19385533034801483\n",
      "Learning Rate at 470: 1.0000000000000004e-08\n",
      "Loss at epoch 480: 0.19385524094104767\n",
      "Learning Rate at 480: 1.0000000000000004e-08\n",
      "Loss at epoch 490: 0.1938551664352417\n",
      "Learning Rate at 490: 1.0000000000000004e-08\n",
      "Loss at epoch 500: 0.19385510683059692\n",
      "Learning Rate at 500: 1.0000000000000004e-08\n",
      "Training Time: 124 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = NN(n_features).to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),  lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001)\n",
    "\n",
    "EPOCH = 500\n",
    "t_start = time.time()\n",
    "model, loss_dict = train(model, optimizer, loss_fn, scheduler, x_train, y_train, EPOCH)\n",
    "t_end = time.time()\n",
    "print(f\"Training Time: {int(t_end - t_start)} seconds\")\n",
    "\n",
    "x_coord, y_coord = zip(*(loss_dict.items()))\n",
    "plt.plot(x_coord,y_coord)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9913ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time: 0.02304863929748535 seconds\n",
      "Accuracy on plain test_set: 0.9423360228538513\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    t_start = time.time()\n",
    "    out = torch.sigmoid(model(x))\n",
    "    t_end = time.time()\n",
    "    print(f\"Prediction Time: {(t_end - t_start)} seconds\")\n",
    "    out_list.append(out)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean(), out\n",
    "\n",
    "out_list = []\n",
    "plain_accuracy, op = accuracy(model, x_test_20, y_test_20)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "95d65941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9423360364539598\n",
      "Recall: 0.9719355103862096\n",
      "Precision: 0.9176284076673208\n",
      "F1 - Score: 0.9440015510772003\n"
     ]
    }
   ],
   "source": [
    "op = op.squeeze().detach().numpy()\n",
    "for i in range(len(op)):\n",
    "    if op[i]<0.5:\n",
    "        op[i] = 0\n",
    "    else:\n",
    "        op[i] = 1\n",
    "y_test_temp = y_test_20.squeeze().numpy()\n",
    "plain_accuracy = accuracy_score(y_test_temp, op)\n",
    "plain_recall = recall_score(y_test_temp, op, average='binary')  \n",
    "plain_f1 = f1_score(y_test_temp, op, average='binary')  \n",
    "plain_precision = precision_score(y_test_temp, op, average='binary')  \n",
    "print(f\"Accuracy: {plain_accuracy}\")\n",
    "print(f\"Recall: {plain_recall}\")\n",
    "print(f\"Precision: {plain_precision}\")\n",
    "print(f\"F1 - Score: {plain_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a58918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
