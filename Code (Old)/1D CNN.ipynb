{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd2d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchmetrics\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4fbf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([681185, 1, 40])\n",
      "y_train shape: torch.Size([681185, 1])\n",
      "x_test shape: torch.Size([170297, 1, 40])\n",
      "y_test shape: torch.Size([170297, 1])\n"
     ]
    }
   ],
   "source": [
    "# Importing, balancing, scaling and splitting the dataset into train and test set\n",
    "df = pd.read_csv(r\"C:\\Users\\manig\\Downloads\\Mitacs\\top_feature_df_rfr40.csv\")\n",
    "\n",
    "grouped = df.groupby('Label')\n",
    "df = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "\n",
    "x = df.drop([\"Label\"], axis = 1)\n",
    "y = df[\"Label\"]\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test_20, y_train, y_test_20 = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train=torch.from_numpy(x_train).float().unsqueeze(dim=1)\n",
    "x_test_20=torch.from_numpy(x_test_20).float().unsqueeze(dim=1)\n",
    "y_train=torch.from_numpy(np.array(y_train)).float().unsqueeze(dim=1)\n",
    "y_test_20=torch.from_numpy(np.array(y_test_20)).float().unsqueeze(dim=1)\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test_20.shape}\")\n",
    "print(f\"y_test shape: {y_test_20.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987036f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19f25e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONEDCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ONEDCNN, self).__init__()\n",
    "        self.conv_layer = torch.nn.Conv1d(in_channels=1, out_channels=3, kernel_size=5, stride=1)\n",
    "        self.dense_layer_1 = torch.nn.Linear(in_features=108, out_features=32)\n",
    "        self.dense_layer_2 = torch.nn.Linear(in_features=32, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x * x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dense_layer_1(x)\n",
    "        x = x * x\n",
    "        x = self.dense_layer_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f65a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy, recall, precision and f1 - score\n",
    "def metrics_fn(y_true, y_pred, others=False):\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i]<0.5:\n",
    "            y_pred[i] = 0\n",
    "        else:\n",
    "            y_pred[i] = 1\n",
    "            \n",
    "    accuracy = torchmetrics.Accuracy(task=\"binary\", num_classes=2)\n",
    "    acc = accuracy(y_pred, y_true)\n",
    "    \n",
    "    if others==True:\n",
    "        rec = torchmetrics.Recall(task=\"binary\", num_classes=2)\n",
    "        prec = torchmetrics.Precision(task=\"binary\", num_classes=2)\n",
    "        recall = rec(y_pred, y_true)\n",
    "        precision = prec(y_pred, y_true)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        del accuracy, rec, prec\n",
    "        return acc, recall, precision, f1_score\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2b2d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
    "    loss_dict = {}\n",
    "    acc_dict = {}\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for data, target in train_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             scheduler.step(loss)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += metrics_fn(target, torch.sigmoid(output))\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        loss_dict[epoch] = train_loss\n",
    "        acc_dict[epoch] = train_acc\n",
    "        if epoch%3 == 0:\n",
    "            print(f\"Epoch: {epoch} Training Loss: {train_loss} || Training Accuracy: {train_acc} || Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    model.eval()\n",
    "    return model, loss_dict, acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c667f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Training Loss: 2.1311208665581285 || Training Accuracy: 0.9430975317955017 || Learning Rate: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m model, loss_dict, acc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m)) \n\u001b[0;32m     10\u001b[0m x_coord, y_coord \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(loss_dict\u001b[38;5;241m.\u001b[39mitems()))\n",
      "Cell \u001b[1;32mIn[19], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, n_epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#             scheduler.step(loss)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m             train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 17\u001b[0m             train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     19\u001b[0m         train_acc \u001b[38;5;241m=\u001b[39m train_acc \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m, in \u001b[0;36mmetrics_fn\u001b[1;34m(y_true, y_pred, others)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred)):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_pred[i]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m         y_pred[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         y_pred[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ONEDCNN()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model, loss_dict, acc_dict = train(model, train_loader, criterion, optimizer, 24)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5)) \n",
    "x_coord, y_coord = zip(*(loss_dict.items()))\n",
    "ax1.plot(x_coord, y_coord)\n",
    "x_coord, y_coord = zip(*(acc_dict.items()))\n",
    "ax2.plot(x_coord, y_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "48cdd5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.1324390023946762,\n",
       "   0.1665675789117813,\n",
       "   -0.16453391313552856,\n",
       "   0.18222437798976898,\n",
       "   -0.17997416853904724],\n",
       "  [0.022764118388295174,\n",
       "   -0.1675294041633606,\n",
       "   0.09291396290063858,\n",
       "   0.18811888992786407,\n",
       "   -0.2205113172531128],\n",
       "  [0.21267381310462952,\n",
       "   -0.14515002071857452,\n",
       "   0.10244119167327881,\n",
       "   -0.0516599640250206,\n",
       "   0.033398158848285675]],\n",
       " [-0.5036184787750244, 1.1617426872253418, -0.11102926731109619])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.weight.data.view(\n",
    "            model.conv_layer.out_channels, model.conv_layer.kernel_size[0]\n",
    "        ).tolist(),model.conv_layer.bias.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "13a5b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = model.conv_layer.bias.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ee8cd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncONEDCNN:\n",
    "    def __init__(self, torch_nn):\n",
    "        self.conv_layer_weight = torch_nn.conv_layer.weight.data.view(\n",
    "            torch_nn.conv_layer.out_channels, torch_nn.conv_layer.kernel_size[0]\n",
    "        ).tolist()\n",
    "        self.conv_layer_bias = torch_nn.conv_layer.bias.data.tolist()\n",
    "        \n",
    "        self.dense_layer_1_weight = torch_nn.dense_layer_1.weight.T.data.tolist()\n",
    "        self.dense_layer_1_bias = torch_nn.dense_layer_1.bias.data.tolist()\n",
    "        \n",
    "        self.dense_layer_2_weight = torch_nn.dense_layer_2.weight.T.data.tolist()\n",
    "        self.dense_layer_2_bias = torch_nn.dense_layer_2.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_channels = []\n",
    "        for kernel, bias in zip(self.conv_layer_weight, self.conv_layer_bias):\n",
    "            y = enc_x.mm(kernel) + bias\n",
    "            enc_channels.append(y)\n",
    "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
    "        enc_x.square_()\n",
    "        enc_x = enc_x.mm(self.dense_layer_1_weight) + self.dense_layer_1_bias\n",
    "        enc_x.squarae_()\n",
    "        enc_x = enc_x.mm(self.dense_layer_2_weight) + self.dense_layer_2_bias\n",
    "        return enc_x\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8671de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2row(x):\n",
    "#     kernel_shape  = kernel.shape[1]\n",
    "    kernel_shape = 5\n",
    "    rows = []\n",
    "    end_neglet = 4 # needs to be changed when the input shape is changed\n",
    "    # Padding = 0, stride = 1\n",
    "    for row in range(x.shape[0] - end_neglet):\n",
    "        window = x[row: row + kernel_shape]\n",
    "        rows.append(window.flatten())\n",
    "    return np.vstack(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4887ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_test(context, model, test_loader, criterion, kernel_shape, stride, tqdm_batch):\n",
    "    tar = []\n",
    "    op = []\n",
    "    acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    for data, target in tqdm(test_loader):\n",
    "        x_enc = []\n",
    "        im2row_matrix = im2row(input_matrix) \n",
    "        for i in im2row_matrix:\n",
    "            x_enc.append(ts.ckks_vector(context, i))\n",
    "#         x_enc = ts.ckks_vector(context, im2row_matrix)\n",
    "        enc_output = enc_model(x_enc)\n",
    "        output = enc_output.decrypt()\n",
    "        print(output)\n",
    "        output = torch.tensor(output).view(1, -1)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        output = torch.sigmoid(output)\n",
    "        for i in range(len(output)):\n",
    "            if output[i]<0.5:\n",
    "                output[i] = 0\n",
    "            else:\n",
    "                output[i] = 1\n",
    "        tar.extend(target)\n",
    "        opt = output.detach()\n",
    "        op.extend(opt)\n",
    "        acc += metrics_fn(y_true=target, y_pred=output)\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    acc /= len(test_loader)\n",
    "    print(f\"Batch {tqdm_batch} Encrypted Accuracy: {acc}\")\n",
    "#     print(f'Accuracy: {acc}')\n",
    "    return tar, op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b7df2cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Batch 1 Encryption & Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8514 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[190], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Encryption & Evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m target, output \u001b[38;5;241m=\u001b[39m \u001b[43menc_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m t_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncryption & Evaluation of the test set took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(t_end \u001b[38;5;241m-\u001b[39m t_start)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[187], line 12\u001b[0m, in \u001b[0;36menc_test\u001b[1;34m(context, model, test_loader, criterion, kernel_shape, stride, tqdm_batch)\u001b[0m\n\u001b[0;32m     10\u001b[0m             x_enc\u001b[38;5;241m.\u001b[39mappend(ts\u001b[38;5;241m.\u001b[39mckks_vector(context, i))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#         x_enc = ts.ckks_vector(context, im2row_matrix)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m         enc_output \u001b[38;5;241m=\u001b[39m \u001b[43menc_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_enc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         output \u001b[38;5;241m=\u001b[39m enc_output\u001b[38;5;241m.\u001b[39mdecrypt()\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(output)\n",
      "Cell \u001b[1;32mIn[189], line 27\u001b[0m, in \u001b[0;36mEncONEDCNN.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[189], line 17\u001b[0m, in \u001b[0;36mEncONEDCNN.forward\u001b[1;34m(self, enc_x)\u001b[0m\n\u001b[0;32m     15\u001b[0m enc_channels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kernel, bias \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layer_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layer_bias):\n\u001b[1;32m---> 17\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43menc_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m(kernel) \u001b[38;5;241m+\u001b[39m bias\n\u001b[0;32m     18\u001b[0m     enc_channels\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[0;32m     19\u001b[0m enc_x \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mCKKSVector\u001b[38;5;241m.\u001b[39mpack_vectors(enc_channels)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'mm'"
     ]
    }
   ],
   "source": [
    "enc_model = EncONEDCNN(model)\n",
    "y_target_final = []\n",
    "y_pred_final = []\n",
    "one_part = y_test_20.shape[0] // 20\n",
    "for i in range(1, 21):\n",
    "    if i==1:\n",
    "        j = one_part\n",
    "        temp_x_test = x_test_20[:j,]\n",
    "        temp_y_test = y_test_20[:j,]\n",
    "    elif i==20:\n",
    "        j = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[j:,]\n",
    "        temp_y_test = y_test_20[j:,]\n",
    "    else:\n",
    "        j = one_part * i\n",
    "        if i == 1:\n",
    "            k = one_part\n",
    "        else:\n",
    "            k = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[k:j,]\n",
    "        temp_y_test = y_test_20[k:j,]\n",
    "    \n",
    "    test_dataset = torch.utils.data.TensorDataset(temp_x_test, temp_y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    enc_x_test = []\n",
    "    print()\n",
    "    print(f\"Starting Batch {i} Encryption & Evaluation\")\n",
    "    target, output = enc_test(ctx_eval, enc_model, test_loader, criterion, kernel_shape, stride, tqdm_batch=i)\n",
    "    t_end = time.time()\n",
    "    print(f\"Encryption & Evaluation of the test set took {int(t_end - t_start)} seconds\")\n",
    "    y_pred_final.extend(output)\n",
    "    y_target_final.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e80a54f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.1324,  0.1666, -0.1645,  0.1822, -0.1800]],\n",
       "\n",
       "        [[ 0.0228, -0.1675,  0.0929,  0.1881, -0.2205]],\n",
       "\n",
       "        [[ 0.2127, -0.1452,  0.1024, -0.0517,  0.0334]]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e552f90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.5036,  1.1617, -0.1110], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e5449bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2row(x, kernel):\n",
    "    kernel_shape = kernel.shape[1]\n",
    "    rows = []\n",
    "    end_neglet = 4 # needs to be changed when the input shape is changed\n",
    "    # Padding = 0, stride = 1\n",
    "    for row in range(x.shape[0] - end_neglet):\n",
    "        window = x[row: row + kernel_shape]\n",
    "        rows.append(window.flatten())\n",
    "    return np.vstack(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "49f4502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape = (input_matrix.shape[0] - kernel.shape[1]) + 1\n",
    "im2row_matrix = im2row(input_matrix, kernel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "df471b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.41859806, -0.5891209 , -0.9327191 , -0.05819717, -1.0278276 ,\n",
       "        -0.18727016, -0.41709524, -0.73032266, -0.33717138, -0.6717379 ,\n",
       "        -0.29773414, -0.4164884 , -0.49897432, -0.46913457, -0.47087964,\n",
       "        -0.5279903 , -0.47726634, -0.43855357, -0.7479829 , -0.36894122,\n",
       "        -0.6947897 , -0.6359041 , -0.45267066, -0.5518055 , -0.49114344,\n",
       "        -0.523178  , -0.5392168 , -0.5925485 , -0.3761148 , -0.5365835 ,\n",
       "        -0.58710253, -0.63822335, -0.6048598 , -0.6683191 , -0.56740606,\n",
       "        -0.55592036], dtype=float32),\n",
       " array([1.16872  , 1.330668 , 0.6467402, 1.618509 , 1.2798402, 0.8283719,\n",
       "        1.2748733, 0.9506574, 1.3799721, 1.2126594, 1.0217606, 1.1820619,\n",
       "        1.1487819, 1.243285 , 1.228684 , 1.0693493, 1.1452988, 1.4423909,\n",
       "        1.0168364, 1.0897014, 1.2773035, 1.1495352, 1.326091 , 1.1542581,\n",
       "        1.0180484, 1.2182463, 1.3834212, 1.1520929, 1.1436352, 1.2405603,\n",
       "        1.2003627, 1.1742232, 1.2116325, 1.1945648, 1.2208644, 1.2573606],\n",
       "       dtype=float32),\n",
       " array([-0.32211295, -0.02070673, -0.20979092, -0.222012  ,  0.0951021 ,\n",
       "        -0.53354037,  0.33676487, -0.22455367, -0.145321  , -0.0344733 ,\n",
       "        -0.24399914,  0.10982929, -0.14554778, -0.10456765, -0.13821429,\n",
       "        -0.1188071 , -0.12167006, -0.14008053, -0.16723844, -0.23907077,\n",
       "         0.0105588 , -0.32521597, -0.1401476 , -0.14085671, -0.14929684,\n",
       "        -0.07502234, -0.19379747, -0.2006951 , -0.18042597, -0.06168819,\n",
       "        -0.23772323, -0.18692642, -0.22703938, -0.19030683, -0.23643456,\n",
       "        -0.1661923 ], dtype=float32)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i, j in zip(kernel, bias):\n",
    "    result.append(np.matmul(im2row_matrix,i) + j)\n",
    "result\n",
    "# result = np.array(result)\n",
    "# result = result.reshape(result[0].shape[0]*kernel.shape[0], 1)\n",
    "# result = result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "670e277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Shape: (5,)\n",
      "Stride: 1\n"
     ]
    }
   ],
   "source": [
    "kernel_shape = model.conv_layer.kernel_size\n",
    "stride = model.conv_layer.stride[0]\n",
    "print(f\"Kernel Shape: {kernel_shape}\\nStride: {stride}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9a7aec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_degree = 16384\n",
    "bits_scale = 31\n",
    "integer_scale = 40\n",
    "coeff_mod_bit_sizes = [integer_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, integer_scale]\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_eval.global_scale = 2 ** bits_scale\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d91be613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Batch 1 Encryption & Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8514 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only encrypt a vector",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Encryption & Evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m target, output \u001b[38;5;241m=\u001b[39m \u001b[43menc_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m t_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncryption & Evaluation of the test set took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(t_end \u001b[38;5;241m-\u001b[39m t_start)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[175], line 8\u001b[0m, in \u001b[0;36menc_test\u001b[1;34m(context, model, test_loader, criterion, kernel_shape, stride, tqdm_batch)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader):\n\u001b[0;32m      7\u001b[0m     im2row_matrix \u001b[38;5;241m=\u001b[39m im2row(input_matrix) \n\u001b[1;32m----> 8\u001b[0m     x_enc \u001b[38;5;241m=\u001b[39m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfv_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2row_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m enc_model(x_enc)\n\u001b[0;32m     10\u001b[0m     output \u001b[38;5;241m=\u001b[39m enc_output\u001b[38;5;241m.\u001b[39mdecrypt()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\tenseal\\__init__.py:86\u001b[0m, in \u001b[0;36mbfv_vector\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbfv_vector\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BFVVector:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124;03m\"\"\"Constructor function for tenseal.BFVVector\"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BFVVector(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\tenseal\\tensors\\bfvvector.py:33\u001b[0m, in \u001b[0;36mBFVVector.__init__\u001b[1;34m(self, context, vector, data)\u001b[0m\n\u001b[0;32m     31\u001b[0m     vector \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mplain_tensor(vector, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vector\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only encrypt a vector\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m vector \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mraw\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39m_ts_cpp\u001b[38;5;241m.\u001b[39mBFVVector(context\u001b[38;5;241m.\u001b[39mdata, vector)\n",
      "\u001b[1;31mValueError\u001b[0m: can only encrypt a vector"
     ]
    }
   ],
   "source": [
    "enc_model = EncONEDCNN(model)\n",
    "y_target_final = []\n",
    "y_pred_final = []\n",
    "one_part = y_test_20.shape[0] // 20\n",
    "for i in range(1, 21):\n",
    "    if i==1:\n",
    "        j = one_part\n",
    "        temp_x_test = x_test_20[:j,]\n",
    "        temp_y_test = y_test_20[:j,]\n",
    "    elif i==20:\n",
    "        j = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[j:,]\n",
    "        temp_y_test = y_test_20[j:,]\n",
    "    else:\n",
    "        j = one_part * i\n",
    "        if i == 1:\n",
    "            k = one_part\n",
    "        else:\n",
    "            k = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[k:j,]\n",
    "        temp_y_test = y_test_20[k:j,]\n",
    "    \n",
    "    test_dataset = torch.utils.data.TensorDataset(temp_x_test, temp_y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    enc_x_test = []\n",
    "    print()\n",
    "    print(f\"Starting Batch {i} Encryption & Evaluation\")\n",
    "    target, output = enc_test(ctx_eval, enc_model, test_loader, criterion, kernel_shape, stride, tqdm_batch=i)\n",
    "    t_end = time.time()\n",
    "    print(f\"Encryption & Evaluation of the test set took {int(t_end - t_start)} seconds\")\n",
    "    y_pred_final.extend(output)\n",
    "    y_target_final.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d6202dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just encrypted our plaintext vector of size: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tenseal.tensors.bfvvector.BFVVector at 0x1dc6646b190>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ts.context(ts.SCHEME_TYPE.BFV, poly_modulus_degree=4096, plain_modulus=1032193)\n",
    "plain_vector = [60, 66, 73, 81, 90]\n",
    "encrypted_vector = ts.bfv_vector(context, plain_vector)\n",
    "print(\"We just encrypted our plaintext vector of size:\", encrypted_vector.size())\n",
    "encrypted_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "30fd4975",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BFVVector' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mencrypted_vector\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'BFVVector' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "encrypted_vector[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4668580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
