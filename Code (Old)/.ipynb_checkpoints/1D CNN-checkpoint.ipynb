{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd2d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchmetrics\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4fbf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([681185, 1, 40])\n",
      "y_train shape: torch.Size([681185, 1])\n",
      "x_test shape: torch.Size([170297, 1, 40])\n",
      "y_test shape: torch.Size([170297, 1])\n"
     ]
    }
   ],
   "source": [
    "# Importing, balancing, scaling and splitting the dataset into train and test set\n",
    "df = pd.read_csv(r\"C:\\Users\\manig\\Downloads\\Mitacs\\top_feature_df_rfr40.csv\")\n",
    "\n",
    "grouped = df.groupby('Label')\n",
    "df = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "\n",
    "x = df.drop([\"Label\"], axis = 1)\n",
    "y = df[\"Label\"]\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test_20, y_train, y_test_20 = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train=torch.from_numpy(x_train).float().unsqueeze(dim=1)\n",
    "x_test_20=torch.from_numpy(x_test_20).float().unsqueeze(dim=1)\n",
    "y_train=torch.from_numpy(np.array(y_train)).float().unsqueeze(dim=1)\n",
    "y_test_20=torch.from_numpy(np.array(y_test_20)).float().unsqueeze(dim=1)\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test_20.shape}\")\n",
    "print(f\"y_test shape: {y_test_20.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987036f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19f25e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONEDCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ONEDCNN, self).__init__()\n",
    "        self.conv_layer = torch.nn.Conv1d(in_channels=1, out_channels=3, kernel_size=5, stride=1)\n",
    "        self.dense_layer_1 = torch.nn.Linear(in_features=108, out_features=32)\n",
    "        self.dense_layer_2 = torch.nn.Linear(in_features=32, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x * x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dense_layer_1(x)\n",
    "        x = x * x\n",
    "        x = self.dense_layer_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f65a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy, recall, precision and f1 - score\n",
    "def metrics_fn(y_true, y_pred, others=False):\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i]<0.5:\n",
    "            y_pred[i] = 0\n",
    "        else:\n",
    "            y_pred[i] = 1\n",
    "            \n",
    "    accuracy = torchmetrics.Accuracy(task=\"binary\", num_classes=2)\n",
    "    acc = accuracy(y_pred, y_true)\n",
    "    \n",
    "    if others==True:\n",
    "        rec = torchmetrics.Recall(task=\"binary\", num_classes=2)\n",
    "        prec = torchmetrics.Precision(task=\"binary\", num_classes=2)\n",
    "        recall = rec(y_pred, y_true)\n",
    "        precision = prec(y_pred, y_true)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        del accuracy, rec, prec\n",
    "        return acc, recall, precision, f1_score\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2b2d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
    "    loss_dict = {}\n",
    "    acc_dict = {}\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for data, target in train_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             scheduler.step(loss)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += metrics_fn(target, torch.sigmoid(output))\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        loss_dict[epoch] = train_loss\n",
    "        acc_dict[epoch] = train_acc\n",
    "        if epoch%3 == 0:\n",
    "            print(f\"Epoch: {epoch} Training Loss: {train_loss} || Training Accuracy: {train_acc} || Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    model.eval()\n",
    "    return model, loss_dict, acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c667f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Training Loss: 2.1311208665581285 || Training Accuracy: 0.9430975317955017 || Learning Rate: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m model, loss_dict, acc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m)) \n\u001b[0;32m     10\u001b[0m x_coord, y_coord \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(loss_dict\u001b[38;5;241m.\u001b[39mitems()))\n",
      "Cell \u001b[1;32mIn[19], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, n_epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#             scheduler.step(loss)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m             train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 17\u001b[0m             train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     19\u001b[0m         train_acc \u001b[38;5;241m=\u001b[39m train_acc \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m, in \u001b[0;36mmetrics_fn\u001b[1;34m(y_true, y_pred, others)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred)):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_pred[i]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m         y_pred[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         y_pred[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ONEDCNN()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model, loss_dict, acc_dict = train(model, train_loader, criterion, optimizer, 24)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5)) \n",
    "x_coord, y_coord = zip(*(loss_dict.items()))\n",
    "ax1.plot(x_coord, y_coord)\n",
    "x_coord, y_coord = zip(*(acc_dict.items()))\n",
    "ax2.plot(x_coord, y_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c5643a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.1324390023946762,\n",
       "   0.1665675789117813,\n",
       "   -0.16453391313552856,\n",
       "   0.18222437798976898,\n",
       "   -0.17997416853904724],\n",
       "  [0.022764118388295174,\n",
       "   -0.1675294041633606,\n",
       "   0.09291396290063858,\n",
       "   0.18811888992786407,\n",
       "   -0.2205113172531128],\n",
       "  [0.21267381310462952,\n",
       "   -0.14515002071857452,\n",
       "   0.10244119167327881,\n",
       "   -0.0516599640250206,\n",
       "   0.033398158848285675]],\n",
       " [-0.5036184787750244, 1.1617426872253418, -0.11102926731109619])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.weight.data.view(\n",
    "            model.conv_layer.out_channels, model.conv_layer.kernel_size[0]\n",
    "        ).tolist(),model.conv_layer.bias.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "efd4243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = model.conv_layer.bias.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fc136348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncONEDCNN:\n",
    "    def __init__(self, torch_nn):\n",
    "        self.conv_layer_weight = torch_nn.conv_layer.weight.data.view(\n",
    "            torch_nn.conv_layer.out_channels, torch_nn.conv_layer.kernel_size[0]\n",
    "        ).tolist()\n",
    "        self.conv_layer_bias = torch_nn.conv_layer.bias.data.tolist()\n",
    "        \n",
    "        self.dense_layer_1_weight = torch_nn.dense_layer_1.weight.T.data.tolist()\n",
    "        self.dense_layer_1_bias = torch_nn.dense_layer_1.bias.data.tolist()\n",
    "        \n",
    "        self.dense_layer_2_weight = torch_nn.dense_layer_2.weight.T.data.tolist()\n",
    "        self.dense_layer_2_bias = torch_nn.dense_layer_2.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_channels = []\n",
    "        for kernel, bias, j in zip(self.conv_layer_weight, self.conv_layer_bias):\n",
    "            y = enc_x.mm(kernel) + bias\n",
    "            enc_channels.append(y)\n",
    "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
    "        enc_x.square_()\n",
    "        enc_x = enc_x.mm(self.dense_layer_1_weight) + self.dense_layer_1_bias\n",
    "        enc_x.squarae_()\n",
    "        enc_x = enc_x.mm(self.dense_layer_2_weight) + self.dense_layer_2_bias\n",
    "        return enc_x\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "05789cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2row(x):\n",
    "#     kernel_shape  = kernel.shape[1]\n",
    "    kernel_shape = 5\n",
    "    rows = []\n",
    "    end_neglet = 4 # needs to be changed when the input shape is changed\n",
    "    # Padding = 0, stride = 1\n",
    "    for row in range(x.shape[0] - end_neglet):\n",
    "        window = x[row: row + kernel_shape]\n",
    "        rows.append(window.flatten())\n",
    "    return np.vstack(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "61c2b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_test(context, model, test_loader, criterion, kernel_shape, stride, tqdm_batch):\n",
    "    tar = []\n",
    "    op = []\n",
    "    acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    for data, target in tqdm(test_loader):\n",
    "        im2row_matrix = im2row(input_matrix) \n",
    "        x_enc = ts.bfv_vector(context, im2row_matrix)\n",
    "        enc_output = enc_model(x_enc)\n",
    "        output = enc_output.decrypt()\n",
    "        print(output)\n",
    "        output = torch.tensor(output).view(1, -1)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        output = torch.sigmoid(output)\n",
    "        for i in range(len(output)):\n",
    "            if output[i]<0.5:\n",
    "                output[i] = 0\n",
    "            else:\n",
    "                output[i] = 1\n",
    "        tar.extend(target)\n",
    "        opt = output.detach()\n",
    "        op.extend(opt)\n",
    "        acc += metrics_fn(y_true=target, y_pred=output)\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    acc /= len(test_loader)\n",
    "    print(f\"Batch {tqdm_batch} Encrypted Accuracy: {acc}\")\n",
    "#     print(f'Accuracy: {acc}')\n",
    "    return tar, op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ff5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e80a54f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.1324,  0.1666, -0.1645,  0.1822, -0.1800]],\n",
       "\n",
       "        [[ 0.0228, -0.1675,  0.0929,  0.1881, -0.2205]],\n",
       "\n",
       "        [[ 0.2127, -0.1452,  0.1024, -0.0517,  0.0334]]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7e9d1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.5036,  1.1617, -0.1110], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b4d77c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2row(x, kernel):\n",
    "    kernel_shape = kernel.shape[1]\n",
    "    rows = []\n",
    "    end_neglet = 4 # needs to be changed when the input shape is changed\n",
    "    # Padding = 0, stride = 1\n",
    "    for row in range(x.shape[0] - end_neglet):\n",
    "        window = x[row: row + kernel_shape]\n",
    "        rows.append(window.flatten())\n",
    "    return np.vstack(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "474e1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape = (input_matrix.shape[0] - kernel.shape[1]) + 1\n",
    "im2row_matrix = im2row(input_matrix, kernel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "154a9d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.41859806, -0.5891209 , -0.9327191 , -0.05819717, -1.0278276 ,\n",
       "        -0.18727016, -0.41709524, -0.73032266, -0.33717138, -0.6717379 ,\n",
       "        -0.29773414, -0.4164884 , -0.49897432, -0.46913457, -0.47087964,\n",
       "        -0.5279903 , -0.47726634, -0.43855357, -0.7479829 , -0.36894122,\n",
       "        -0.6947897 , -0.6359041 , -0.45267066, -0.5518055 , -0.49114344,\n",
       "        -0.523178  , -0.5392168 , -0.5925485 , -0.3761148 , -0.5365835 ,\n",
       "        -0.58710253, -0.63822335, -0.6048598 , -0.6683191 , -0.56740606,\n",
       "        -0.55592036], dtype=float32),\n",
       " array([1.16872  , 1.330668 , 0.6467402, 1.618509 , 1.2798402, 0.8283719,\n",
       "        1.2748733, 0.9506574, 1.3799721, 1.2126594, 1.0217606, 1.1820619,\n",
       "        1.1487819, 1.243285 , 1.228684 , 1.0693493, 1.1452988, 1.4423909,\n",
       "        1.0168364, 1.0897014, 1.2773035, 1.1495352, 1.326091 , 1.1542581,\n",
       "        1.0180484, 1.2182463, 1.3834212, 1.1520929, 1.1436352, 1.2405603,\n",
       "        1.2003627, 1.1742232, 1.2116325, 1.1945648, 1.2208644, 1.2573606],\n",
       "       dtype=float32),\n",
       " array([-0.32211295, -0.02070673, -0.20979092, -0.222012  ,  0.0951021 ,\n",
       "        -0.53354037,  0.33676487, -0.22455367, -0.145321  , -0.0344733 ,\n",
       "        -0.24399914,  0.10982929, -0.14554778, -0.10456765, -0.13821429,\n",
       "        -0.1188071 , -0.12167006, -0.14008053, -0.16723844, -0.23907077,\n",
       "         0.0105588 , -0.32521597, -0.1401476 , -0.14085671, -0.14929684,\n",
       "        -0.07502234, -0.19379747, -0.2006951 , -0.18042597, -0.06168819,\n",
       "        -0.23772323, -0.18692642, -0.22703938, -0.19030683, -0.23643456,\n",
       "        -0.1661923 ], dtype=float32)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i, j in zip(kernel, bias):\n",
    "    result.append(np.matmul(im2row_matrix,i) + j)\n",
    "result\n",
    "# result = np.array(result)\n",
    "# result = result.reshape(result[0].shape[0]*kernel.shape[0], 1)\n",
    "# result = result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fb4348c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.08502043038606644],\n",
       " [-0.08550245314836502],\n",
       " [-0.4291006028652191],\n",
       " [0.4454213082790375],\n",
       " [-0.5242091417312622],\n",
       " [0.3163483142852783],\n",
       " [0.08652324229478836],\n",
       " [-0.2267041802406311],\n",
       " [0.16644708812236786],\n",
       " [-0.16811946034431458],\n",
       " [0.20588435232639313],\n",
       " [0.08713008463382721],\n",
       " [0.004644157364964485],\n",
       " [0.03448391333222389],\n",
       " [0.032738830894231796],\n",
       " [-0.0243717972189188],\n",
       " [0.02635214850306511],\n",
       " [0.0650649145245552],\n",
       " [-0.2443644404411316],\n",
       " [0.13467726111412048],\n",
       " [-0.19117124378681183],\n",
       " [-0.13228559494018555],\n",
       " [0.050947822630405426],\n",
       " [-0.0481870174407959],\n",
       " [0.012475050985813141],\n",
       " [-0.019559532403945923],\n",
       " [-0.03559832274913788],\n",
       " [-0.08892998099327087],\n",
       " [0.12750369310379028],\n",
       " [-0.032964982092380524],\n",
       " [-0.08348408341407776],\n",
       " [-0.13460487127304077],\n",
       " [-0.10124132037162781],\n",
       " [-0.16470065712928772],\n",
       " [-0.0637875646352768],\n",
       " [-0.05230185389518738],\n",
       " [0.006977267563343048],\n",
       " [0.16892531514167786],\n",
       " [-0.5150024890899658],\n",
       " [0.4567663371562958],\n",
       " [0.11809756606817245],\n",
       " [-0.33337077498435974],\n",
       " [0.11313056200742722],\n",
       " [-0.211085245013237],\n",
       " [0.21822941303253174],\n",
       " [0.05091668665409088],\n",
       " [-0.13998207449913025],\n",
       " [0.020319240167737007],\n",
       " [-0.012960833497345448],\n",
       " [0.08154231309890747],\n",
       " [0.06694132089614868],\n",
       " [-0.09239338338375092],\n",
       " [-0.016443811357021332],\n",
       " [0.28064823150634766],\n",
       " [-0.14490634202957153],\n",
       " [-0.07204122841358185],\n",
       " [0.11556074023246765],\n",
       " [-0.012207566760480404],\n",
       " [0.164348304271698],\n",
       " [-0.0074845850467681885],\n",
       " [-0.14369423687458038],\n",
       " [0.05650363117456436],\n",
       " [0.22167852520942688],\n",
       " [-0.00964975357055664],\n",
       " [-0.01810753345489502],\n",
       " [0.07881763577461243],\n",
       " [0.0386199951171875],\n",
       " [0.012480512261390686],\n",
       " [0.049889758229255676],\n",
       " [0.03282207250595093],\n",
       " [0.05912178009748459],\n",
       " [0.09561793506145477],\n",
       " [-0.21108368039131165],\n",
       " [0.09032253921031952],\n",
       " [-0.09876164048910141],\n",
       " [-0.1109827309846878],\n",
       " [0.20613136887550354],\n",
       " [-0.4225110709667206],\n",
       " [0.4477941393852234],\n",
       " [-0.1135244071483612],\n",
       " [-0.03429172560572624],\n",
       " [0.07655596733093262],\n",
       " [-0.13296987116336823],\n",
       " [0.22085855901241302],\n",
       " [-0.03451851010322571],\n",
       " [0.006461609620600939],\n",
       " [-0.027185026556253433],\n",
       " [-0.007777830120176077],\n",
       " [-0.010640792548656464],\n",
       " [-0.02905126102268696],\n",
       " [-0.056209176778793335],\n",
       " [-0.12804150581359863],\n",
       " [0.12158806622028351],\n",
       " [-0.21418669819831848],\n",
       " [-0.029118334874510765],\n",
       " [-0.029827449470758438],\n",
       " [-0.03826756402850151],\n",
       " [0.03600692376494408],\n",
       " [-0.08276820927858353],\n",
       " [-0.08966583758592606],\n",
       " [-0.06939670443534851],\n",
       " [0.04934107884764671],\n",
       " [-0.1266939640045166],\n",
       " [-0.07589715719223022],\n",
       " [-0.11601011455059052],\n",
       " [-0.07927756011486053],\n",
       " [-0.12540529668331146],\n",
       " [-0.055163025856018066]]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e01ab3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = x_train[1].squeeze().numpy()\n",
    "kernel = model.conv_layer.weight.detach().squeeze().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b8daa9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "980d1db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.36093259e-01 -4.33108769e-02 -6.85816765e-01  1.37509161e-03\n",
      "  -3.52203220e-01]\n",
      " [-4.33108769e-02 -6.85816765e-01  1.37509161e-03 -3.52203220e-01\n",
      "  -5.49382687e-01]\n",
      " [-6.85816765e-01  1.37509161e-03 -3.52203220e-01 -5.49382687e-01\n",
      "   1.64656532e+00]\n",
      " [ 1.37509161e-03 -3.52203220e-01 -5.49382687e-01  1.64656532e+00\n",
      "  -6.30470634e-01]\n",
      " [-3.52203220e-01 -5.49382687e-01  1.64656532e+00 -6.30470634e-01\n",
      "   1.39703159e-03]\n",
      " [-5.49382687e-01  1.64656532e+00 -6.30470634e-01  1.39703159e-03\n",
      "  -6.03155531e-02]\n",
      " [ 1.64656532e+00 -6.30470634e-01  1.39703159e-03 -6.03155531e-02\n",
      "   8.50646347e-02]\n",
      " [-6.30470634e-01  1.39703159e-03 -6.03155531e-02  8.50646347e-02\n",
      "   9.38261151e-01]\n",
      " [ 1.39703159e-03 -6.03155531e-02  8.50646347e-02  9.38261151e-01\n",
      "  -1.07407875e-01]\n",
      " [-6.03155531e-02  8.50646347e-02  9.38261151e-01 -1.07407875e-01\n",
      "   1.95710547e-03]\n",
      " [ 8.50646347e-02  9.38261151e-01 -1.07407875e-01  1.95710547e-03\n",
      "  -1.12825766e-01]\n",
      " [ 9.38261151e-01 -1.07407875e-01  1.95710547e-03 -1.12825766e-01\n",
      "  -9.11242794e-03]\n",
      " [-1.07407875e-01  1.95710547e-03 -1.12825766e-01 -9.11242794e-03\n",
      "  -9.11242794e-03]\n",
      " [ 1.95710547e-03 -1.12825766e-01 -9.11242794e-03 -9.11242794e-03\n",
      "  -2.95481503e-01]\n",
      " [-1.12825766e-01 -9.11242794e-03 -9.11242794e-03 -2.95481503e-01\n",
      "  -5.64213336e-01]\n",
      " [-9.11242794e-03 -9.11242794e-03 -2.95481503e-01 -5.64213336e-01\n",
      "  -1.80856913e-01]\n",
      " [-9.11242794e-03 -2.95481503e-01 -5.64213336e-01 -1.80856913e-01\n",
      "  -9.39075649e-02]\n",
      " [-2.95481503e-01 -5.64213336e-01 -1.80856913e-01 -9.39075649e-02\n",
      "  -1.03088677e+00]\n",
      " [-5.64213336e-01 -1.80856913e-01 -9.39075649e-02 -1.03088677e+00\n",
      "  -1.82726339e-01]\n",
      " [-1.80856913e-01 -9.39075649e-02 -1.03088677e+00 -1.82726339e-01\n",
      "  -2.10880727e-01]\n",
      " [-9.39075649e-02 -1.03088677e+00 -1.82726339e-01 -2.10880727e-01\n",
      "  -7.45124836e-03]\n",
      " [-1.03088677e+00 -1.82726339e-01 -2.10880727e-01 -7.45124836e-03\n",
      "  -7.45136943e-03]\n",
      " [-1.82726339e-01 -2.10880727e-01 -7.45124836e-03 -7.45136943e-03\n",
      "  -6.13452733e-01]\n",
      " [-2.10880727e-01 -7.45124836e-03 -7.45136943e-03 -6.13452733e-01\n",
      "  -5.08645177e-01]\n",
      " [-7.45124836e-03 -7.45136943e-03 -6.13452733e-01 -5.08645177e-01\n",
      "  -3.58763859e-02]\n",
      " [-7.45136943e-03 -6.13452733e-01 -5.08645177e-01 -3.58763859e-02\n",
      "  -3.58763859e-02]\n",
      " [-6.13452733e-01 -5.08645177e-01 -3.58763859e-02 -3.58763859e-02\n",
      "  -7.27911174e-01]\n",
      " [-5.08645177e-01 -3.58763859e-02 -3.58763859e-02 -7.27911174e-01\n",
      "  -6.17591977e-01]\n",
      " [-3.58763859e-02 -3.58763859e-02 -7.27911174e-01 -6.17591977e-01\n",
      "  -7.27911174e-01]\n",
      " [-3.58763859e-02 -7.27911174e-01 -6.17591977e-01 -7.27911174e-01\n",
      "  -6.89327776e-01]\n",
      " [-7.27911174e-01 -6.17591977e-01 -7.27911174e-01 -6.89327776e-01\n",
      "  -6.75856948e-01]\n",
      " [-6.17591977e-01 -7.27911174e-01 -6.89327776e-01 -6.75856948e-01\n",
      "  -4.34365779e-01]\n",
      " [-7.27911174e-01 -6.89327776e-01 -6.75856948e-01 -4.34365779e-01\n",
      "  -4.33022201e-01]\n",
      " [-6.89327776e-01 -6.75856948e-01 -4.34365779e-01 -4.33022201e-01\n",
      "  -2.58972675e-01]\n",
      " [-6.75856948e-01 -4.34365779e-01 -4.33022201e-01 -2.58972675e-01\n",
      "  -4.11269069e-01]\n",
      " [-4.34365779e-01 -4.33022201e-01 -2.58972675e-01 -4.11269069e-01\n",
      "  -6.09454393e-01]]\n"
     ]
    }
   ],
   "source": [
    "output_shape = (input_matrix.shape[0] - kernel.shape[1]) + 1\n",
    "im2row_matrix = im2row(input_matrix, kernel) \n",
    "print(im2row_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06faa6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 5)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im2row_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ad06f25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.36093259e-01, -4.33108769e-02, -6.85816765e-01,  1.37509161e-03,\n",
       "       -3.52203220e-01, -5.49382687e-01,  1.64656532e+00, -6.30470634e-01,\n",
       "        1.39703159e-03, -6.03155531e-02,  8.50646347e-02,  9.38261151e-01,\n",
       "       -1.07407875e-01,  1.95710547e-03, -1.12825766e-01, -9.11242794e-03,\n",
       "       -9.11242794e-03, -2.95481503e-01, -5.64213336e-01, -1.80856913e-01,\n",
       "       -9.39075649e-02, -1.03088677e+00, -1.82726339e-01, -2.10880727e-01,\n",
       "       -7.45124836e-03, -7.45136943e-03, -6.13452733e-01, -5.08645177e-01,\n",
       "       -3.58763859e-02, -3.58763859e-02, -7.27911174e-01, -6.17591977e-01,\n",
       "       -7.27911174e-01, -6.89327776e-01, -6.75856948e-01, -4.34365779e-01,\n",
       "       -4.33022201e-01, -2.58972675e-01, -4.11269069e-01, -6.09454393e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c4a0775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.132439  ,  0.16656758, -0.16453391,  0.18222438, -0.17997417],\n",
       "       [ 0.02276412, -0.1675294 ,  0.09291396,  0.18811889, -0.22051132],\n",
       "       [ 0.21267381, -0.14515002,  0.10244119, -0.05165996,  0.03339816]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b53ee17f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in kernel:\n",
    "    result.append(np.matmul(im2row_matrix,i))\n",
    "result = np.array(result)\n",
    "result = result.reshape(result[0].shape[0]*kernel.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d0ecc612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c8565e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "da94637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4aa9d492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08502043],\n",
       "       [-0.08550245],\n",
       "       [-0.4291006 ],\n",
       "       [ 0.4454213 ],\n",
       "       [-0.52420914],\n",
       "       [ 0.3163483 ],\n",
       "       [ 0.08652324],\n",
       "       [-0.22670418],\n",
       "       [ 0.16644709],\n",
       "       [-0.16811946],\n",
       "       [ 0.20588435],\n",
       "       [ 0.08713008],\n",
       "       [ 0.00464416],\n",
       "       [ 0.03448391],\n",
       "       [ 0.03273883],\n",
       "       [-0.0243718 ],\n",
       "       [ 0.02635215],\n",
       "       [ 0.06506491],\n",
       "       [-0.24436444],\n",
       "       [ 0.13467726],\n",
       "       [-0.19117124],\n",
       "       [-0.1322856 ],\n",
       "       [ 0.05094782],\n",
       "       [-0.04818702],\n",
       "       [ 0.01247505],\n",
       "       [-0.01955953],\n",
       "       [-0.03559832],\n",
       "       [-0.08892998],\n",
       "       [ 0.1275037 ],\n",
       "       [-0.03296498],\n",
       "       [-0.08348408],\n",
       "       [-0.13460487],\n",
       "       [-0.10124132],\n",
       "       [-0.16470066],\n",
       "       [-0.06378756],\n",
       "       [-0.05230185],\n",
       "       [ 0.00697727],\n",
       "       [ 0.16892532],\n",
       "       [-0.5150025 ],\n",
       "       [ 0.45676634],\n",
       "       [ 0.11809757],\n",
       "       [-0.33337077],\n",
       "       [ 0.11313056],\n",
       "       [-0.21108525],\n",
       "       [ 0.21822941],\n",
       "       [ 0.05091669],\n",
       "       [-0.13998207],\n",
       "       [ 0.02031924],\n",
       "       [-0.01296083],\n",
       "       [ 0.08154231],\n",
       "       [ 0.06694132],\n",
       "       [-0.09239338],\n",
       "       [-0.01644381],\n",
       "       [ 0.28064823],\n",
       "       [-0.14490634],\n",
       "       [-0.07204123],\n",
       "       [ 0.11556074],\n",
       "       [-0.01220757],\n",
       "       [ 0.1643483 ],\n",
       "       [-0.00748459],\n",
       "       [-0.14369424],\n",
       "       [ 0.05650363],\n",
       "       [ 0.22167853],\n",
       "       [-0.00964975],\n",
       "       [-0.01810753],\n",
       "       [ 0.07881764],\n",
       "       [ 0.03862   ],\n",
       "       [ 0.01248051],\n",
       "       [ 0.04988976],\n",
       "       [ 0.03282207],\n",
       "       [ 0.05912178],\n",
       "       [ 0.09561794],\n",
       "       [-0.21108368],\n",
       "       [ 0.09032254],\n",
       "       [-0.09876164],\n",
       "       [-0.11098273],\n",
       "       [ 0.20613137],\n",
       "       [-0.42251107],\n",
       "       [ 0.44779414],\n",
       "       [-0.11352441],\n",
       "       [-0.03429173],\n",
       "       [ 0.07655597],\n",
       "       [-0.13296987],\n",
       "       [ 0.22085856],\n",
       "       [-0.03451851],\n",
       "       [ 0.00646161],\n",
       "       [-0.02718503],\n",
       "       [-0.00777783],\n",
       "       [-0.01064079],\n",
       "       [-0.02905126],\n",
       "       [-0.05620918],\n",
       "       [-0.1280415 ],\n",
       "       [ 0.12158807],\n",
       "       [-0.2141867 ],\n",
       "       [-0.02911833],\n",
       "       [-0.02982745],\n",
       "       [-0.03826756],\n",
       "       [ 0.03600692],\n",
       "       [-0.08276821],\n",
       "       [-0.08966584],\n",
       "       [-0.0693967 ],\n",
       "       [ 0.04934108],\n",
       "       [-0.12669396],\n",
       "       [-0.07589716],\n",
       "       [-0.11601011],\n",
       "       [-0.07927756],\n",
       "       [-0.1254053 ],\n",
       "       [-0.05516303]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.reshape(result[0].shape[0]*kernel.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "71d4fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.36093259e-01 -4.33108769e-02 -6.85816765e-01]\n",
      " [-4.33108769e-02 -6.85816765e-01  1.37509161e-03]\n",
      " [-6.85816765e-01  1.37509161e-03 -3.52203220e-01]\n",
      " [ 1.37509161e-03 -3.52203220e-01 -5.49382687e-01]\n",
      " [-3.52203220e-01 -5.49382687e-01  1.64656532e+00]\n",
      " [-5.49382687e-01  1.64656532e+00 -6.30470634e-01]\n",
      " [ 1.64656532e+00 -6.30470634e-01  1.39703159e-03]\n",
      " [-6.30470634e-01  1.39703159e-03 -6.03155531e-02]\n",
      " [ 1.39703159e-03 -6.03155531e-02  8.50646347e-02]\n",
      " [-6.03155531e-02  8.50646347e-02  9.38261151e-01]\n",
      " [ 8.50646347e-02  9.38261151e-01 -1.07407875e-01]\n",
      " [ 9.38261151e-01 -1.07407875e-01  1.95710547e-03]\n",
      " [-1.07407875e-01  1.95710547e-03 -1.12825766e-01]\n",
      " [ 1.95710547e-03 -1.12825766e-01 -9.11242794e-03]\n",
      " [-1.12825766e-01 -9.11242794e-03 -9.11242794e-03]\n",
      " [-9.11242794e-03 -9.11242794e-03 -2.95481503e-01]\n",
      " [-9.11242794e-03 -2.95481503e-01 -5.64213336e-01]\n",
      " [-2.95481503e-01 -5.64213336e-01 -1.80856913e-01]\n",
      " [-5.64213336e-01 -1.80856913e-01 -9.39075649e-02]\n",
      " [-1.80856913e-01 -9.39075649e-02 -1.03088677e+00]\n",
      " [-9.39075649e-02 -1.03088677e+00 -1.82726339e-01]\n",
      " [-1.03088677e+00 -1.82726339e-01 -2.10880727e-01]\n",
      " [-1.82726339e-01 -2.10880727e-01 -7.45124836e-03]\n",
      " [-2.10880727e-01 -7.45124836e-03 -7.45136943e-03]\n",
      " [-7.45124836e-03 -7.45136943e-03 -6.13452733e-01]\n",
      " [-7.45136943e-03 -6.13452733e-01 -5.08645177e-01]\n",
      " [-6.13452733e-01 -5.08645177e-01 -3.58763859e-02]\n",
      " [-5.08645177e-01 -3.58763859e-02 -3.58763859e-02]\n",
      " [-3.58763859e-02 -3.58763859e-02 -7.27911174e-01]\n",
      " [-3.58763859e-02 -7.27911174e-01 -6.17591977e-01]\n",
      " [-7.27911174e-01 -6.17591977e-01 -7.27911174e-01]\n",
      " [-6.17591977e-01 -7.27911174e-01 -6.89327776e-01]\n",
      " [-7.27911174e-01 -6.89327776e-01 -6.75856948e-01]\n",
      " [-6.89327776e-01 -6.75856948e-01 -4.34365779e-01]\n",
      " [-6.75856948e-01 -4.34365779e-01 -4.33022201e-01]\n",
      " [-4.34365779e-01 -4.33022201e-01 -2.58972675e-01]\n",
      " [-4.33022201e-01 -2.58972675e-01 -4.11269069e-01]\n",
      " [-2.58972675e-01 -4.11269069e-01 -6.09454393e-01]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (15,) and (38,3) not aligned: 15 (dim 0) != 38 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m im2row_matrix \u001b[38;5;241m=\u001b[39m im2row(input_matrix, kernel) \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(im2row_matrix)\n\u001b[1;32m----> 4\u001b[0m im2row_conv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2row_matrix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m bias\n\u001b[0;32m      5\u001b[0m im2row_conv \u001b[38;5;241m=\u001b[39m im2row_conv\u001b[38;5;241m.\u001b[39mreshape(output_shape,output_shape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(im2row_conv)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (15,) and (38,3) not aligned: 15 (dim 0) != 38 (dim 0)"
     ]
    }
   ],
   "source": [
    "output_shape = (input_matrix.shape[0] - kernel.shape[0]) + 1\n",
    "im2row_matrix = im2row(input_matrix, kernel) \n",
    "print(im2row_matrix)\n",
    "im2row_conv = np.dot(kernel.flatten(), im2row_matrix) + bias\n",
    "im2row_conv = im2row_conv.reshape(output_shape,output_shape)\n",
    "\n",
    "print(im2row_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "880f7721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.36093259e-01, -4.33108769e-02, -6.85816765e-01,\n",
       "         1.37509161e-03, -3.52203220e-01, -5.49382687e-01,\n",
       "         1.64656532e+00, -6.30470634e-01,  1.39703159e-03,\n",
       "        -6.03155531e-02,  8.50646347e-02,  9.38261151e-01,\n",
       "        -1.07407875e-01,  1.95710547e-03, -1.12825766e-01,\n",
       "        -9.11242794e-03, -9.11242794e-03, -2.95481503e-01,\n",
       "        -5.64213336e-01, -1.80856913e-01, -9.39075649e-02,\n",
       "        -1.03088677e+00, -1.82726339e-01, -2.10880727e-01,\n",
       "        -7.45124836e-03, -7.45136943e-03, -6.13452733e-01,\n",
       "        -5.08645177e-01, -3.58763859e-02, -3.58763859e-02,\n",
       "        -7.27911174e-01, -6.17591977e-01, -7.27911174e-01,\n",
       "        -6.89327776e-01, -6.75856948e-01, -4.34365779e-01,\n",
       "        -4.33022201e-01, -2.58972675e-01, -4.11269069e-01,\n",
       "        -6.09454393e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29b6e451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.kernel_size[0], model.conv_layer.out_channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8960469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.1324390023946762,\n",
       "  0.1665675789117813,\n",
       "  -0.16453391313552856,\n",
       "  0.18222437798976898,\n",
       "  -0.17997416853904724],\n",
       " [0.022764118388295174,\n",
       "  -0.1675294041633606,\n",
       "  0.09291396290063858,\n",
       "  0.18811888992786407,\n",
       "  -0.2205113172531128],\n",
       " [0.21267381310462952,\n",
       "  -0.14515002071857452,\n",
       "  0.10244119167327881,\n",
       "  -0.0516599640250206,\n",
       "  0.033398158848285675]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_layer.weight.data.view(\n",
    "            model.conv_layer.out_channels, model.conv_layer.kernel_size[0]\n",
    "        ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b8fdb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Shape: (5,)\n",
      "Stride: 1\n"
     ]
    }
   ],
   "source": [
    "kernel_shape = model.conv_layer.kernel_size\n",
    "stride = model.conv_layer.stride[0]\n",
    "print(f\"Kernel Shape: {kernel_shape}\\nStride: {stride}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "82c184a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_degree = 16384\n",
    "bits_scale = 31\n",
    "integer_scale = 40\n",
    "coeff_mod_bit_sizes = [integer_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, integer_scale]\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_eval.global_scale = 2 ** bits_scale\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "74b37c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Batch 1 Encryption & Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8514 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only encrypt a vector",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Encryption & Evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m target, output \u001b[38;5;241m=\u001b[39m \u001b[43menc_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m t_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncryption & Evaluation of the test set took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(t_end \u001b[38;5;241m-\u001b[39m t_start)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[175], line 8\u001b[0m, in \u001b[0;36menc_test\u001b[1;34m(context, model, test_loader, criterion, kernel_shape, stride, tqdm_batch)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader):\n\u001b[0;32m      7\u001b[0m     im2row_matrix \u001b[38;5;241m=\u001b[39m im2row(input_matrix) \n\u001b[1;32m----> 8\u001b[0m     x_enc \u001b[38;5;241m=\u001b[39m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfv_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2row_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m enc_model(x_enc)\n\u001b[0;32m     10\u001b[0m     output \u001b[38;5;241m=\u001b[39m enc_output\u001b[38;5;241m.\u001b[39mdecrypt()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\tenseal\\__init__.py:86\u001b[0m, in \u001b[0;36mbfv_vector\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbfv_vector\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BFVVector:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124;03m\"\"\"Constructor function for tenseal.BFVVector\"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BFVVector(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\tenseal\\tensors\\bfvvector.py:33\u001b[0m, in \u001b[0;36mBFVVector.__init__\u001b[1;34m(self, context, vector, data)\u001b[0m\n\u001b[0;32m     31\u001b[0m     vector \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mplain_tensor(vector, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vector\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only encrypt a vector\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m vector \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mraw\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39m_ts_cpp\u001b[38;5;241m.\u001b[39mBFVVector(context\u001b[38;5;241m.\u001b[39mdata, vector)\n",
      "\u001b[1;31mValueError\u001b[0m: can only encrypt a vector"
     ]
    }
   ],
   "source": [
    "enc_model = EncONEDCNN(model)\n",
    "y_target_final = []\n",
    "y_pred_final = []\n",
    "one_part = y_test_20.shape[0] // 20\n",
    "for i in range(1, 21):\n",
    "    if i==1:\n",
    "        j = one_part\n",
    "        temp_x_test = x_test_20[:j,]\n",
    "        temp_y_test = y_test_20[:j,]\n",
    "    elif i==20:\n",
    "        j = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[j:,]\n",
    "        temp_y_test = y_test_20[j:,]\n",
    "    else:\n",
    "        j = one_part * i\n",
    "        if i == 1:\n",
    "            k = one_part\n",
    "        else:\n",
    "            k = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[k:j,]\n",
    "        temp_y_test = y_test_20[k:j,]\n",
    "    \n",
    "    test_dataset = torch.utils.data.TensorDataset(temp_x_test, temp_y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    enc_x_test = []\n",
    "    print()\n",
    "    print(f\"Starting Batch {i} Encryption & Evaluation\")\n",
    "    target, output = enc_test(ctx_eval, enc_model, test_loader, criterion, kernel_shape, stride, tqdm_batch=i)\n",
    "    t_end = time.time()\n",
    "    print(f\"Encryption & Evaluation of the test set took {int(t_end - t_start)} seconds\")\n",
    "    y_pred_final.extend(output)\n",
    "    y_target_final.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f6a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
