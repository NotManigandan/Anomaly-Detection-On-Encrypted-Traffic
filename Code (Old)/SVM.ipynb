{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dece4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import shuffle, random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchmetrics\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8888dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing, balancing, scaling and splitting the dataset into train and test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmanig\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMitacs\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtop_feature_df_rfr40.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m grouped \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# Importing, balancing, scaling and splitting the dataset into train and test set\n",
    "df = pd.read_csv(r\"C:\\Users\\manig\\Downloads\\Mitacs\\top_feature_df_rfr40.csv\")\n",
    "df['Label'] = df['Label'].replace(0, -1)\n",
    "        \n",
    "grouped = df.groupby('Label')\n",
    "df = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "\n",
    "x = df.drop([\"Label\"], axis = 1)\n",
    "y = df[\"Label\"]\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test_20, y_train, y_test_20 = train_test_split(x, y, test_size=0.02, random_state=42)\n",
    "x_train=torch.from_numpy(x_train).float().unsqueeze(dim=1)\n",
    "x_test_20=torch.from_numpy(x_test_20).float().unsqueeze(dim=1)\n",
    "y_train=torch.from_numpy(np.array(y_train)).float().unsqueeze(dim=1)\n",
    "y_test_20=torch.from_numpy(np.array(y_test_20)).float().unsqueeze(dim=1)\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test_20.shape}\")\n",
    "print(f\"y_test shape: {y_test_20.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(SVM, self).__init__()\n",
    "        self.dense_layer_1 = nn.Linear(n_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.dense_layer_1(x)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, y, model):\n",
    "    correct = 0\n",
    "    for i in range(len(y)):\n",
    "        y_predicted = model(X[i]).squeeze().detach()\n",
    "        y_predicted = torch.sign(y_predicted).float()\n",
    "        if y_predicted == y[i]: \n",
    "            correct += 1\n",
    "    return float(correct)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd139eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, optimizer, epoch, batchsize, step, model):\n",
    "    loss_dict = {}\n",
    "    acc_dict = {}\n",
    "    model.train()\n",
    "    for epoch in range(epoch):\n",
    "        perm = torch.randperm(len(X))\n",
    "        train_loss = 0.0\n",
    "        for i in range(0, len(X), batchsize):\n",
    "            x = X[perm[i : i + batchsize]]\n",
    "            y = Y[perm[i : i + batchsize]]\n",
    "            output = model(x).squeeze()\n",
    "            weight = model.dense_layer_1.weight.squeeze()\n",
    "            loss = torch.mean(torch.clamp(1 - y * output, min=0))\n",
    "            loss += step * (weight.t() @ weight) / 2.0\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += float(loss)\n",
    "        loss_dict[epoch] = train_loss / len(X)\n",
    "        acc = accuracy(X, Y, model)\n",
    "        acc_dict[epoch] = acc\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"Epoch: {epoch+1}\\tLoss: {train_loss / len(X)}\\tAccuracy: {acc}\")\n",
    "            \n",
    "            \n",
    "    model.eval()\n",
    "    return model, loss_dict, acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bde634",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = SVM(40)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "epoch = 100\n",
    "batchsize = 64\n",
    "step = 0.01\n",
    "model, loss_dict, acc_dict = train(x_train, y_train, optimizer, epoch, batchsize, step, model)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5)) \n",
    "x_coord, y_coord = zip(*(loss_dict.items()))\n",
    "ax1.plot(x_coord, y_coord)\n",
    "x_coord, y_coord = zip(*(acc_dict.items()))\n",
    "ax2.plot(x_coord, y_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = SVM(40)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "epoch = 100\n",
    "batchsize = 64\n",
    "step = 0.01\n",
    "model, loss_dict, acc_dict = train(x_train, y_train, optimizer, epoch, batchsize, step, model)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5)) \n",
    "x_coord, y_coord = zip(*(loss_dict.items()))\n",
    "ax1.plot(x_coord, y_coord)\n",
    "x_coord, y_coord = zip(*(acc_dict.items()))\n",
    "ax2.plot(x_coord, y_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fea49836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_NAME = \"svm.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bec63727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\svm.pth\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d1aa01e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVM(40)\n",
    "model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9613a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedSVM:\n",
    "    \n",
    "    def __init__(self, torch_svm):\n",
    "        self.weight = torch_svm.dense_layer_1.weight.data.tolist()[0]\n",
    "        self.bias = torch_svm.dense_layer_1.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b718d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encsvm = EncryptedSVM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "357ebfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [60, 40, 60]\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_eval.global_scale = 2 ** 40\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "710e6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy, recall, precision and f1 - score\n",
    "def metrics_fn(y_true, y_pred, others=False):\n",
    "    y_true = (y_true + 1) / 2\n",
    "    y_pred = (y_pred + 1) / 2\n",
    "            \n",
    "    accuracy = torchmetrics.Accuracy(task=\"binary\", num_classes=2)\n",
    "    acc = accuracy(y_pred, y_true)\n",
    "    \n",
    "    if others==True:\n",
    "        rec = torchmetrics.Recall(task=\"binary\", num_classes=2)\n",
    "        prec = torchmetrics.Precision(task=\"binary\", num_classes=2)\n",
    "        recall = rec(y_pred, y_true)\n",
    "        precision = prec(y_pred, y_true)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        del accuracy, rec, prec\n",
    "        return acc, recall, precision, f1_score\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47d783d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time.time()\n",
    "    output_list = []\n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        enc_out = model(enc_x)\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sign(out).float()\n",
    "        output_list.append(out)\n",
    "    t_end = time.time()\n",
    "    print(f\"Evaluated test set of {len(enc_x_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    accuracy = metrics_fn(torch.stack(output_list), y_test)\n",
    "#     print(f\"Score: {correct}/{len(enc_x_test)}\")\n",
    "    return accuracy, output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a3715dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7743354439735413\n",
      "Recall: 0.9646798968315125\n",
      "Precision: 0.5695917010307312\n",
      "F1 - Score: 0.7162664532661438\n"
     ]
    }
   ],
   "source": [
    "out = model(x_test_20).detach().squeeze().unsqueeze(dim=1)\n",
    "out = torch.sign(out).float()\n",
    "acc, rec, prec, f1 = metrics_fn(out, y_test_20, True)\n",
    "print(f\"Accuracy: {acc}\\nRecall: {rec}\\nPrecision: {prec}\\nF1 - Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4c6d7a51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Batch 1 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:04<00:00, 206.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 4 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 1 Encrypted Accuracy: 0.7779083251953125\n",
      "\n",
      "Starting Batch 2 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 234.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 2 Encrypted Accuracy: 0.7591069340705872\n",
      "\n",
      "Starting Batch 3 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 236.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 3 Encrypted Accuracy: 0.7591069340705872\n",
      "\n",
      "Starting Batch 4 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 238.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 8 seconds\n",
      "Batch 4 Encrypted Accuracy: 0.7403055429458618\n",
      "\n",
      "Starting Batch 5 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 213.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 8 seconds\n",
      "Batch 5 Encrypted Accuracy: 0.7649824023246765\n",
      "\n",
      "Starting Batch 6 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 237.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 6 Encrypted Accuracy: 0.7661574482917786\n",
      "\n",
      "Starting Batch 7 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 236.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 8 seconds\n",
      "Batch 7 Encrypted Accuracy: 0.7438308000564575\n",
      "\n",
      "Starting Batch 8 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 237.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 8 seconds\n",
      "Batch 8 Encrypted Accuracy: 0.7661574482917786\n",
      "\n",
      "Starting Batch 9 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 236.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 8 seconds\n",
      "Batch 9 Encrypted Accuracy: 0.7708578109741211\n",
      "\n",
      "Starting Batch 10 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 237.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 10 Encrypted Accuracy: 0.7426556944847107\n",
      "\n",
      "Starting Batch 11 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 238.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 11 Encrypted Accuracy: 0.7978848218917847\n",
      "\n",
      "Starting Batch 12 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 236.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 8 seconds\n",
      "Batch 12 Encrypted Accuracy: 0.7626321911811829\n",
      "\n",
      "Starting Batch 13 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 238.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 13 Encrypted Accuracy: 0.760282039642334\n",
      "\n",
      "Starting Batch 14 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 238.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 14 Encrypted Accuracy: 0.7978848218917847\n",
      "\n",
      "Starting Batch 15 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 238.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 15 Encrypted Accuracy: 0.7673325538635254\n",
      "\n",
      "Starting Batch 16 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 238.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 16 Encrypted Accuracy: 0.7708578109741211\n",
      "\n",
      "Starting Batch 17 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 236.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 17 Encrypted Accuracy: 0.7661574482917786\n",
      "\n",
      "Starting Batch 18 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 238.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 18 Encrypted Accuracy: 0.7955346703529358\n",
      "\n",
      "Starting Batch 19 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 851/851 [00:03<00:00, 239.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 851 entries in 7 seconds\n",
      "Batch 19 Encrypted Accuracy: 0.7497062087059021\n",
      "\n",
      "Starting Batch 20 Encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 861/861 [00:03<00:00, 239.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test set took 3 seconds\n",
      "Evaluated test set of 861 entries in 8 seconds\n",
      "Batch 20 Encrypted Accuracy: 0.7781649231910706\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = []\n",
    "parts = 20\n",
    "one_part = y_test_20.shape[0] // parts\n",
    "for i in range(1, parts+1):\n",
    "    if i==1:\n",
    "        j = one_part\n",
    "        temp_x_test = x_test_20[:j,]\n",
    "        temp_y_test = y_test_20[:j,]\n",
    "    elif i==parts:\n",
    "        j = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[j:,]\n",
    "        temp_y_test = y_test_20[j:,]\n",
    "    else:\n",
    "        j = one_part * i\n",
    "        if i == 1:\n",
    "            k = one_part\n",
    "        else:\n",
    "            k = one_part * (i-1)\n",
    "        temp_x_test = x_test_20[k:j,]\n",
    "        temp_y_test = y_test_20[k:j,]\n",
    "    \n",
    "    t_start = time.time()\n",
    "    enc_x_test = []\n",
    "    print()\n",
    "    print(f\"Starting Batch {i} Encryption\")\n",
    "    for x in tqdm(range(len(temp_x_test))):\n",
    "        enc_x_test.append(ts.ckks_vector(ctx_eval, temp_x_test[x].squeeze().tolist()))\n",
    "    t_end = time.time()\n",
    "    print(f\"Encryption of the test set took {int(t_end - t_start)} seconds\")\n",
    "    encrypted_accuracy, output_list = encrypted_evaluation(eelr, enc_x_test, temp_y_test)\n",
    "    print(f\"Batch {i} Encrypted Accuracy: {encrypted_accuracy}\")\n",
    "    y_pred = torch.cat(output_list)\n",
    "    y_pred = y_pred.numpy()\n",
    "    y_pred_final.extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b40a4294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7668820023536682\n",
      "Recall: 0.9485703110694885\n",
      "Precision: 0.5627945065498352\n",
      "F1 - Score: 0.7064477205276489\n"
     ]
    }
   ],
   "source": [
    "out = model(x_test_20).detach().squeeze().unsqueeze(dim=1)\n",
    "out = torch.sign(out).float()\n",
    "acc, rec, prec, f1 = metrics_fn((torch.tensor(y_pred_final)).unsqueeze(dim=1), y_test_20, True)\n",
    "print(f\"Accuracy: {acc}\\nRecall: {rec}\\nPrecision: {prec}\\nF1 - Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
